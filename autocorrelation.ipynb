{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb096d3e",
   "metadata": {},
   "source": [
    "## MCMC Convergence/Autocorrelation\n",
    "This notebook runs a chain for the fiducial cosmology for about 10e^6 samples and looks at the autocorrelation time $\\tau$ each 100 iterations. In general we want at least $50\\tau$ samples. We will assume the autocorrelation time is similar for each cosmology. We can always choose a conservative estimate for the number of samples to ensure the chains converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b93cd523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from getdist import plots, MCSamples\n",
    "import getdist\n",
    "from multiprocessing import Pool\n",
    "from getdist import plots, MCSamples\n",
    "\n",
    "import sys\n",
    "import time\n",
    "from cocoa_emu import *\n",
    "from cocoa_emu.emulator import NNEmulator, GPEmulator\n",
    "from cocoa_emu.data_model import LSST_3x2\n",
    "\n",
    "import emcee\n",
    "import time\n",
    "\n",
    "from numpy import linalg\n",
    "import scipy\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db5f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "def plot_cosmo_contours(sample_list, legend_labels):\n",
    "    names = ['logA', 'ns', 'H0', 'omegab', 'omegac']\n",
    "    labels =  ['logA', 'ns', 'H0', 'omega b', 'omega c']\n",
    "    \n",
    "    cosmo_truth = [3.0675, 0.97, 69., 0.0228528, 0.1199772]\n",
    "    \n",
    "    truth_dict = {}\n",
    "    for name, truth in zip(names, cosmo_truth):\n",
    "        truth_dict[name] = truth\n",
    "        \n",
    "    getdist_samples = []\n",
    "    for samples, legend_label in zip(sample_list, legend_labels):\n",
    "        cosmo_samples = samples[:,:5]\n",
    "        getdist_samples.append(MCSamples(samples=cosmo_samples,names = names, labels=labels, label=legend_label))\n",
    "    \n",
    "    g = plots.get_subplot_plotter()\n",
    "    g.triangle_plot(getdist_samples, filled=True, markers=truth_dict)\n",
    "    \n",
    "    #plt.show()\n",
    "    \n",
    "def add_bias(bias_theta, datavector):\n",
    "    for i in range(5):\n",
    "        factor = (bias_theta[i] / bias_fid[i])**bias_mask[i]\n",
    "        datavector = factor * datavector\n",
    "    return datavector\n",
    "\n",
    "def add_shear_calib(m, datavector):\n",
    "    for i in range(5):\n",
    "        factor = (1 + m[i])**shear_calib_mask[i]\n",
    "        datavector = factor * datavector\n",
    "    return datavector\n",
    "\n",
    "def hard_prior(theta, params_prior):\n",
    "    \"\"\"\n",
    "    A function to impose a flat prior on a set of parameters.\n",
    "    :theta: The set of parameter values\n",
    "    :params_prior: The minimum and the maximum value of the parameters on which this prior is imposed\n",
    "    \"\"\"\n",
    "    is_lower_than_min = bool(np.sum(theta < params_prior[:,0]))\n",
    "    is_higher_than_max = bool(np.sum(theta > params_prior[:,1]))\n",
    "    if is_lower_than_min or is_higher_than_max:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return 0.\n",
    "    \n",
    "cosmo_prior_lim = np.array([[1.61, 3.91],\n",
    "                       [0.87, 1.07],\n",
    "                       [55, 91],\n",
    "                       [0.01, 0.04],\n",
    "                       [0.001, 0.99]])\n",
    "\n",
    "ia_prior_lim = np.array([[-5., 5.],\n",
    "                       [-5., 5.]])\n",
    "\n",
    "bias_prior_lim = np.array([[0.8, 3.],\n",
    "                       [0.8, 3.],\n",
    "                       [0.8, 3.],\n",
    "                       [0.8, 3.],\n",
    "                       [0.8, 3.]])\n",
    "\n",
    "baryon_prior_lim = np.array([[-3., 12.],\n",
    "                             [-2.5, 2.5]])\n",
    "\n",
    "baryon_prior_lim = 3. * baryon_prior_lim \n",
    "\n",
    "dz_source_std   = 0.002 * np.ones(5)\n",
    "dz_lens_std     = 0.005 * np.ones(5)\n",
    "shear_calib_std = 0.005 * np.ones(5)\n",
    "    \n",
    "def lnprior(theta):\n",
    "    cosmo_theta = theta[:5]\n",
    "    ns          = cosmo_theta[1]\n",
    "\n",
    "    ns_prior    = 0.\n",
    "    \n",
    "    dz_source   = theta[5:10]\n",
    "    ia_theta    = theta[10:12]\n",
    "    dz_lens     = theta[12:17]\n",
    "    bias        = theta[17:22]\n",
    "    shear_calib = theta[22:27]\n",
    "    baryon_q    = theta[27:]\n",
    "    \n",
    "    cosmo_prior = hard_prior(cosmo_theta, cosmo_prior_lim) + ns_prior\n",
    "    ia_prior    = hard_prior(ia_theta, ia_prior_lim)\n",
    "    bias_prior  = hard_prior(bias, bias_prior_lim)\n",
    "    baryon_prior = hard_prior(baryon_q, baryon_prior_lim)\n",
    "    \n",
    "    dz_source_lnprior   = -0.5 * np.sum((dz_source / dz_source_std)**2)\n",
    "    dz_lens_lnprior     = -0.5 * np.sum((dz_lens / dz_lens_std)**2)\n",
    "    shear_calib_lnprior = -0.5 * np.sum((shear_calib / shear_calib_std)**2)\n",
    "    \n",
    "    return cosmo_prior + ia_prior + dz_source_lnprior + dz_lens_lnprior + \\\n",
    "            shear_calib_lnprior + bias_prior + baryon_prior\n",
    "    \n",
    "def ln_lkl(theta):\n",
    "    model_datavector = get_data_vector_emu(theta)\n",
    "    delta_dv = (model_datavector - data_model.dv_obs)[data_model.mask_3x2]\n",
    "    return -0.5 * delta_dv @ data_model.masked_inv_cov @ delta_dv\n",
    "\n",
    "def lnprob(theta):\n",
    "    return lnprior(theta) + ln_lkl(theta)\n",
    "\n",
    "def get_data_vector_emu(theta):\n",
    "    \"\"\"\n",
    "    Function to get the emulated data vector (including the effect of galaxy bias, baryons, etc.)\n",
    "    \"\"\"\n",
    "    cosmo_ia_dz_theta = theta[:17]\n",
    "    bias        = theta[17:22]\n",
    "    shear_calib = theta[22:27]\n",
    "    baryon_q    = theta[27:]\n",
    "    datavector = data_model.compute_datavector(cosmo_ia_dz_theta)\n",
    "    datavector = np.array(datavector)\n",
    "    datavector = add_bias(bias, datavector)\n",
    "    datavector = add_shear_calib(shear_calib, datavector)\n",
    "    return datavector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c733f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WALKERS     = 120\n",
    "N_MCMC        = 200000\n",
    "N_SAMPLES     = N_WALKERS*N_MCMC\n",
    "NDIM_SAMPLING = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1403cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the necessary data for likelihood\n",
    "\n",
    "# Get the LSST covariance and fid data\n",
    "path = '/home/grads/data/evan/tension_calibration/data/lsst_y1/'\n",
    "lsst_cov = np.loadtxt(path+'cov_lsst_y1')\n",
    "fid_cos = np.loadtxt(path+'lsst_y1_data_fid',dtype=np.float32)[:,1]\n",
    "\n",
    "lsst_y1_cov = np.zeros((1560, 1560))\n",
    "for line in lsst_cov:\n",
    "    i = int(line[0])\n",
    "    j = int(line[1])\n",
    "\n",
    "    cov_g_block  = line[-2]\n",
    "    cov_ng_block = line[-1]\n",
    "\n",
    "    cov_ij = cov_g_block + cov_ng_block\n",
    "\n",
    "    lsst_y1_cov[i,j] = cov_ij\n",
    "    lsst_y1_cov[j,i] = cov_ij\n",
    "    \n",
    "fid = torch.Tensor(fid_cos)\n",
    "cov = torch.Tensor(lsst_y1_cov)\n",
    "\n",
    "# Code taken from the emulator notebook\n",
    "#first the fiducial cosmology\n",
    "\n",
    "configfile = 'configs/nn_emu.yaml'\n",
    "config = Config(configfile)\n",
    "\n",
    "config_args     = config.config_args\n",
    "config_args_io  = config_args['io']\n",
    "config_args_data = config_args['data']\n",
    "\n",
    "savedir = 'output/nn_emu/'\n",
    "\n",
    "N_DIM         = 17\n",
    "data_model    = LSST_3x2(N_DIM, config_args_io, config_args_data)\n",
    "data_model.emu_type = 'nn'\n",
    "OUTPUT_DIM = 1560\n",
    "\n",
    "emu = NNEmulator(N_DIM, OUTPUT_DIM, data_model.dv_fid, data_model.dv_std)    \n",
    "emu.load('model/nn_emu/model')\n",
    "# ======================================================\n",
    "\n",
    "data_model.emu = emu\n",
    "\n",
    "bias_fid         = data_model.bias_fid\n",
    "bias_mask        = data_model.bias_mask\n",
    "shear_calib_mask = data_model.shear_calib_mask\n",
    "\n",
    "theta0    = np.array([3.0675, 0.97, 69.0, 0.0228528, 0.1199772, \n",
    "                      0., 0., 0., 0., 0.,\n",
    "                      0.5, 0.,\n",
    "                      0., 0., 0., 0., 0.,\n",
    "                      1.24, 1.36, 1.47, 1.60, 1.76,\n",
    "                      0., 0., 0., 0., 0.,\n",
    "                      0., 0.])\n",
    "\n",
    "theta_std = np.array([0.01, 0.001, 0.1, 0.001, 0.002, \n",
    "                      0.002, 0.002, 0.002, 0.002, 0.002, \n",
    "                      0.1, 0.1,\n",
    "                      0.005, 0.005, 0.005, 0.005, 0.005, \n",
    "                      0.03, 0.03, 0.03, 0.03, 0.03,\n",
    "                      0.005, 0.005, 0.005, 0.005, 0.005, \n",
    "                      0.1, 0.1]) \n",
    "\n",
    "# Starting position of the emcee chain\n",
    "pos0 = theta0[np.newaxis] + 3. * theta_std[np.newaxis] * np.random.normal(size=(N_WALKERS, NDIM_SAMPLING))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e755bd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MCMC ---\n",
      "N_iterations = 200000\n",
      "N_walkers = 120\n",
      "N_samples = 24000000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200000/200000 [4:14:52<00:00, 13.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    for sample in emu_sampler.sample(pos0, iterations=N_MCMC, progress=True):\\n        if(emu_sampler.iteration % 10000):\\n            continue\\n\\n        # Compute the autocorrelation time so far\\n        # Using tol=0 means that we'll always get an estimate even\\n        # if it isn't trustworthy\\n        tau = emu_sampler.get_autocorr_time(tol=0)\\n        atau = np.mean(tau)\\n        autocorr[index] = atau\\n        autocorr_ratio[index] = atau/aold_tau\\n        index += 1\\n\\n        old_tau = tau\\n        aold_tau = np.mean(old_tau)\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autocorr       = np.zeros(N_MCMC)\n",
    "autocorr_ratio = np.zeros(N_MCMC)\n",
    "\n",
    "index = 0\n",
    "old_tau=np.inf\n",
    "aold_tau=0\n",
    "\n",
    "print('--- MCMC ---')\n",
    "print('N_iterations = {}'.format(N_MCMC))\n",
    "print('N_walkers = {}'.format(N_WALKERS))\n",
    "print('N_samples = {}\\n'.format(N_SAMPLES))\n",
    "\n",
    "filename = \"godzilla.h5\"\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "backend.reset(N_WALKERS, NDIM_SAMPLING) ### comment if you do not want the previous chain erased !!!!!!!!\n",
    "\n",
    "with Pool(10) as pool:\n",
    "    emu_sampler = emcee.EnsembleSampler(N_WALKERS, NDIM_SAMPLING, lnprob, pool=pool, backend=backend)\n",
    "    emu_sampler.run_mcmc(pos0, N_MCMC, progress=True)\n",
    "'''\n",
    "    for sample in emu_sampler.sample(pos0, iterations=N_MCMC, progress=True):\n",
    "        if(emu_sampler.iteration % 10000):\n",
    "            continue\n",
    "\n",
    "        # Compute the autocorrelation time so far\n",
    "        # Using tol=0 means that we'll always get an estimate even\n",
    "        # if it isn't trustworthy\n",
    "        tau = emu_sampler.get_autocorr_time(tol=0)\n",
    "        atau = np.mean(tau)\n",
    "        autocorr[index] = atau\n",
    "        autocorr_ratio[index] = atau/aold_tau\n",
    "        index += 1\n",
    "\n",
    "        old_tau = tau\n",
    "        aold_tau = np.mean(old_tau)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90c3cffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nf, (ax1, ax2) = plt.subplots(1, 2, sharey=False)\\nn = 1000 * np.arange(2, index + 1)\\nprint(n)\\nprint(autocorr)\\n\\nax1.plot(n,autocorr[1:index])\\nax1.plot(n,n/50,'k--',label='iterations/50')\\nax1.set_ylabel('tau')\\nax1.set_xlabel('iterations')\\nax1.set_ylim(0,1250)\\nax1.legend()\\nax2.plot(n,autocorr_ratio[1:index])\\nax2.plot([0,N_MCMC],[1,1],color='k')\\nax2.plot([0,N_MCMC],[0.99,0.99],'k--')\\nax2.plot([0,N_MCMC],[1.01,1.01],'k--')\\nax2.set_xlabel('iterations')\\nax2.set_ylabel('tau / prev. tau')\\nax2.set_ylim(0.98,1.05)\\n#ax3.plot(n,autocorr_diff[1:index])\\n#ax3.set_ylim(-0.01,1.1)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=False)\n",
    "n = 1000 * np.arange(2, index + 1)\n",
    "print(n)\n",
    "print(autocorr)\n",
    "\n",
    "ax1.plot(n,autocorr[1:index])\n",
    "ax1.plot(n,n/50,'k--',label='iterations/50')\n",
    "ax1.set_ylabel('tau')\n",
    "ax1.set_xlabel('iterations')\n",
    "ax1.set_ylim(0,1250)\n",
    "ax1.legend()\n",
    "ax2.plot(n,autocorr_ratio[1:index])\n",
    "ax2.plot([0,N_MCMC],[1,1],color='k')\n",
    "ax2.plot([0,N_MCMC],[0.99,0.99],'k--')\n",
    "ax2.plot([0,N_MCMC],[1.01,1.01],'k--')\n",
    "ax2.set_xlabel('iterations')\n",
    "ax2.set_ylabel('tau / prev. tau')\n",
    "ax2.set_ylim(0.98,1.05)\n",
    "#ax3.plot(n,autocorr_diff[1:index])\n",
    "#ax3.set_ylim(-0.01,1.1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74c5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(autocorr[:index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "342fb97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.07534296e+00  9.68475514e-01  6.87605433e+01 ...  1.16508062e-02\n",
      "  -5.01119927e-01  1.10234833e-01]\n",
      " [ 3.06723652e+00  9.73372822e-01  6.89360831e+01 ...  1.54206219e-02\n",
      "   1.91042641e-01 -6.34389417e-02]\n",
      " [ 3.04302129e+00  9.69618015e-01  6.93401232e+01 ... -1.22156168e-03\n",
      "  -3.91580667e-01 -3.68599706e-01]\n",
      " ...\n",
      " [ 3.16067819e+00  9.99156048e-01  6.51764827e+01 ... -4.21112546e-03\n",
      "  -1.50140945e+00 -5.67746438e+00]\n",
      " [ 3.01789088e+00  9.57851043e-01  7.67322775e+01 ...  1.37380611e-03\n",
      "   2.15472479e+01 -2.23244786e+00]\n",
      " [ 3.06321669e+00  9.74909949e-01  6.70803599e+01 ... -2.34321228e-03\n",
      "   8.69703376e+00  1.97733852e+00]]\n"
     ]
    }
   ],
   "source": [
    "filename = \"godzilla.h5\"\n",
    "reader = emcee.backends.HDFBackend(filename)\n",
    "\n",
    "samples = reader.get_chain(flat=True)\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aee306e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2341.99534268 2247.25560561 2240.18575022 2091.91863711 2338.91995198\n",
      "  887.46367363  890.26328236  891.69624243  916.67869511  890.89165756\n",
      "  918.93087129  873.74329085  902.10421134  926.57282835  914.66225069\n",
      "  922.99498757  908.14471594  996.23355772  974.02796871  966.1156263\n",
      "  969.17281602  964.48349499  890.6920013   886.77576723  852.15243163\n",
      "  892.50844566  902.21546636 1023.86765241 1019.04366777]\n"
     ]
    }
   ],
   "source": [
    "autocorr = reader.get_autocorr_time()\n",
    "print(autocorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5083ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1153.162444511595\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(autocorr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced5517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emu",
   "language": "python",
   "name": "emu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
