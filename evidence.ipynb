{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfdcfb09",
   "metadata": {},
   "source": [
    "## Bayesian Evidence\n",
    "In this notebook I will use the posterior estimate to estimate the evidence.\n",
    "$$ \\frac{\\mathcal{P}(\\theta)}{\\Pi(\\theta)\\mathcal{L}(\\theta)} = \\mathcal{E} $$\n",
    "$$ \\log(\\mathcal{P}(\\theta)) - \\log(\\Pi(\\theta)) - \\log(\\mathcal{L}(\\theta)) = \\log(\\mathcal{E}) $$\n",
    "The posterior will be estimated using normalizing flows. The evidence will be approximated two ways:\n",
    "1. On a dense grid. This tells us if the evidence is well approximated in the entire parameter space\n",
    "2. For each sample. This tells us if the evidence is well approximated in the highly populated regions of the parameter space.\n",
    "The evidence will be approximated as a function of chain length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7a8dad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import getdist\n",
    "from getdist import plots, MCSamples, WeightedSamples\n",
    "\n",
    "import sys\n",
    "import datetime \n",
    "from cocoa_emu import *\n",
    "from cocoa_emu.emulator import NNEmulator, GPEmulator\n",
    "from cocoa_emu.data_model import LSST_3x2\n",
    "import emcee\n",
    "\n",
    "# Now normalizing flow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "tfk = tf.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from numpy import linalg\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20501d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "### open the long chain\n",
    "filename = \"/home/grads/ownCloud/StatisticalProject/chains/godzilla.h5\"\n",
    "reader = emcee.backends.HDFBackend(filename, read_only=True)\n",
    "\n",
    "#all samples\n",
    "samples = reader.get_chain(flat=True)\n",
    "#remove burn in and thin\n",
    "samples_thin = reader.get_chain(flat=True, thin=1000, discard=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ef25ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of chain lengths:\n",
    "chain_lengths = [100,500,1000,5000,10000,20000,30000,40000,50000,75000,100000,125000,250000,500000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de913b2b",
   "metadata": {},
   "source": [
    "Lets do a single chain length as an example first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e87fb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSST EMULATOR FUNCTIONS\n",
    "def add_bias(bias_theta, datavector):\n",
    "    for i in range(5):\n",
    "        factor = (bias_theta[i] / bias_fid[i])**bias_mask[i]\n",
    "        datavector = factor * datavector\n",
    "    return datavector\n",
    "\n",
    "def add_shear_calib(m, datavector):\n",
    "    for i in range(5):\n",
    "        factor = (1 + m[i])**shear_calib_mask[i]\n",
    "        datavector = factor * datavector\n",
    "    return datavector\n",
    "\n",
    "def hard_prior(theta, params_prior):\n",
    "    \"\"\"\n",
    "    A function to impose a flat prior on a set of parameters.\n",
    "    :theta: The set of parameter values\n",
    "    :params_prior: The minimum and the maximum value of the parameters on which this prior is imposed\n",
    "    \"\"\"\n",
    "    is_lower_than_min = bool(np.sum(theta < params_prior[:,0]))\n",
    "    is_higher_than_max = bool(np.sum(theta > params_prior[:,1]))\n",
    "    if is_lower_than_min or is_higher_than_max:\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return 0.\n",
    "    \n",
    "cosmo_prior_lim = np.array([[1.61, 3.91],\n",
    "                       [0.87, 1.07],\n",
    "                       [55, 91],\n",
    "                       [0.01, 0.04],\n",
    "                       [0.001, 0.99]])\n",
    "\n",
    "ia_prior_lim = np.array([[-5., 5.],\n",
    "                       [-5., 5.]])\n",
    "\n",
    "bias_prior_lim = np.array([[0.8, 3.],\n",
    "                       [0.8, 3.],\n",
    "                       [0.8, 3.],\n",
    "                       [0.8, 3.],\n",
    "                       [0.8, 3.]])\n",
    "\n",
    "baryon_prior_lim = np.array([[-3., 12.],\n",
    "                             [-2.5, 2.5]])\n",
    "\n",
    "baryon_prior_lim = 3. * baryon_prior_lim \n",
    "\n",
    "dz_source_std   = 0.002 * np.ones(5)\n",
    "dz_lens_std     = 0.005 * np.ones(5)\n",
    "shear_calib_std = 0.005 * np.ones(5)\n",
    "    \n",
    "def lnprior(theta):\n",
    "    cosmo_theta = theta[:5]\n",
    "    ns          = cosmo_theta[1]\n",
    "\n",
    "    ns_prior    = 0.\n",
    "    \n",
    "    dz_source   = theta[5:10]\n",
    "    ia_theta    = theta[10:12]\n",
    "    dz_lens     = theta[12:17]\n",
    "    bias        = theta[17:22]\n",
    "    shear_calib = theta[22:27]\n",
    "    baryon_q    = theta[27:]\n",
    "    \n",
    "    cosmo_prior = hard_prior(cosmo_theta, cosmo_prior_lim) + ns_prior\n",
    "    ia_prior    = hard_prior(ia_theta, ia_prior_lim)\n",
    "    bias_prior  = hard_prior(bias, bias_prior_lim)\n",
    "    baryon_prior = hard_prior(baryon_q, baryon_prior_lim)\n",
    "    \n",
    "    dz_source_lnprior   = -0.5 * np.sum((dz_source / dz_source_std)**2)\n",
    "    dz_lens_lnprior     = -0.5 * np.sum((dz_lens / dz_lens_std)**2)\n",
    "    shear_calib_lnprior = -0.5 * np.sum((shear_calib / shear_calib_std)**2)\n",
    "    \n",
    "    return cosmo_prior + ia_prior + dz_source_lnprior + dz_lens_lnprior + \\\n",
    "            shear_calib_lnprior + bias_prior + baryon_prior\n",
    "    \n",
    "def ln_lkl(theta):\n",
    "    model_datavector = get_data_vector_emu(theta)[0]\n",
    "    delta_dv = (model_datavector - data_model.dv_obs)[data_model.mask_3x2]\n",
    "    return -0.5 * delta_dv @ data_model.masked_inv_cov @ delta_dv\n",
    "\n",
    "def lnprob(theta):\n",
    "    return lnprior(theta) + ln_lkl(theta)\n",
    "\n",
    "def get_data_vector_emu(theta):\n",
    "    \"\"\"\n",
    "    Function to get the emulated data vector (including the effect of galaxy bias, baryons, etc.)\n",
    "    \"\"\"\n",
    "    cosmo_ia_dz_theta = theta[:17]\n",
    "    bias        = theta[17:22]\n",
    "    shear_calib = theta[22:27]\n",
    "    baryon_q    = theta[27:]\n",
    "    datavector = data_model.compute_datavector(cosmo_ia_dz_theta)\n",
    "    datavector = np.array(datavector)\n",
    "    datavector = add_bias(bias, datavector)\n",
    "    datavector = add_shear_calib(shear_calib, datavector)\n",
    "    return datavector\n",
    "\n",
    "### Get the necessary data for likelihood\n",
    "\n",
    "# Get the LSST covariance and fid data\n",
    "path = '/home/grads/data/evan/LSST_emulation/data/lsst_y1/'\n",
    "lsst_cov = np.loadtxt(path+'cov_lsst_y1')\n",
    "fid_cos = np.loadtxt(path+'lsst_y1_data_fid',dtype=np.float32)[:,1]\n",
    "\n",
    "lsst_y1_cov = np.zeros((1560, 1560))\n",
    "for line in lsst_cov:\n",
    "    i = int(line[0])\n",
    "    j = int(line[1])\n",
    "\n",
    "    cov_g_block  = line[-2]\n",
    "    cov_ng_block = line[-1]\n",
    "\n",
    "    cov_ij = cov_g_block + cov_ng_block\n",
    "\n",
    "    lsst_y1_cov[i,j] = cov_ij\n",
    "    lsst_y1_cov[j,i] = cov_ij\n",
    "    \n",
    "fid = torch.Tensor(fid_cos)\n",
    "cov = torch.Tensor(lsst_y1_cov)\n",
    "\n",
    "# Code taken from the emulator notebook\n",
    "#first the fiducial cosmology\n",
    "\n",
    "configfile = 'configs/nn_emu.yaml'\n",
    "config = Config(configfile)\n",
    "\n",
    "config_args     = config.config_args\n",
    "config_args_io  = config_args['io']\n",
    "config_args_data = config_args['data']\n",
    "\n",
    "savedir = 'output/nn_emu/'\n",
    "\n",
    "N_DIM         = 17\n",
    "data_model    = LSST_3x2(N_DIM, config_args_io, config_args_data)\n",
    "data_model.emu_type = 'nn'\n",
    "OUTPUT_DIM = 1560\n",
    "\n",
    "emu = NNEmulator(N_DIM, OUTPUT_DIM, data_model.dv_fid, data_model.dv_std)    \n",
    "emu.load('model/nn_emu/model')\n",
    "# ======================================================\n",
    "\n",
    "data_model.emu = emu\n",
    "\n",
    "bias_fid         = data_model.bias_fid\n",
    "bias_mask        = data_model.bias_mask\n",
    "shear_calib_mask = data_model.shear_calib_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6743d5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Compute value at each sample\n",
    "length_eg = samples[:100]\n",
    "prior_lkl = np.array([lnprob(s) for s in length_eg])\n",
    "print(len(prior_lkl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d311227",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NORMALIZING FLOW FUNCTIONS\n",
    "\n",
    "class Callback(tfk.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self._loss = []\n",
    "        self._epoch = []\n",
    "        self.n_epochs = self.params['epochs']\n",
    "        print('[                    ] Training... ',end=\"\")\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        progress = int(epoch/self.n_epochs*20)\n",
    "        ret = '\\r['\n",
    "        for i in range(progress):\n",
    "            ret += '#'\n",
    "        for i in range(20-progress):\n",
    "            ret += ' '\n",
    "        print(ret+'] Training... (epoch {}/{})'.format(epoch,self.n_epochs),end=\"\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self._loss.append(logs['loss'])\n",
    "        self._epoch.append(epoch)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print('\\r'+'[####################] Completed!                          ')\n",
    "        fig,ax1 = plt.subplots(1,1)\n",
    "        \n",
    "        ax1.set_title('loss vs. epoch')\n",
    "        ax1.set_xlabel('epoch')\n",
    "        ax1.set_ylabel('loss')\n",
    "        ax1.plot(self._epoch,self._loss)\n",
    "        \n",
    "class No_Plot_Callback(tfk.callbacks.Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.n_epochs = self.params['epochs']\n",
    "        print('[                    ] Training... ',end=\"\")\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        progress = int(epoch/self.n_epochs*20)\n",
    "        ret = '\\r['\n",
    "        for i in range(progress):\n",
    "            ret += '#'\n",
    "        for i in range(20-progress):\n",
    "            ret += ' '\n",
    "        print(ret+'] Training... (epoch {}/{})'.format(epoch,self.n_epochs),end=\"\")\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print('\\r'+'[####################] Completed!                             ')\n",
    "\n",
    "def pregauss(chain,data):\n",
    "    covmat = chain.cov().astype(np.float32)\n",
    "    mean = chain.getMeans().astype(np.float32)\n",
    "    \n",
    "    # bijector time!\n",
    "    # TriL means the cov matrix is lower triangular. Inverse is easy to compute that way\n",
    "    # the cholesky factorization takes a positive definite hermitian matrix M (like the covmat) to LL^T with L lower triangluar\n",
    "    gauss_approx = tfd.MultivariateNormalTriL(loc=mean,scale_tril=tf.linalg.cholesky(covmat))\n",
    "    bijector = gauss_approx.bijector\n",
    "\n",
    "    # now map the data\n",
    "    new_data = bijector.inverse(data.astype(np.float32))\n",
    "    return new_data,bijector\n",
    "\n",
    "def train(base,data,bijectors,batch_size,n_epochs,feedback=True):\n",
    "    val_split = 0.1\n",
    "    # stack data\n",
    "    _data = []\n",
    "    dim = 0\n",
    "    for key in data.getParamNames().list():\n",
    "        nsamples=len(data[key])\n",
    "        _data.append(data[key])\n",
    "        dim += 1\n",
    "\n",
    "    xdata = np.stack(_data, axis=-1)\n",
    "\n",
    "    x_data,bij = pregauss(data,xdata)\n",
    "\n",
    "    #create data set with weights.\n",
    "    weights = data.weights.astype(np.float32)\n",
    "    \n",
    "    ## NN setup\n",
    "    target_distribution = tfd.TransformedDistribution(\n",
    "        distribution=base,\n",
    "        bijector=tfb.Chain(bijectors)) \n",
    "\n",
    "    # Construct model.\n",
    "    x_ = tfk.Input(shape=(dim,), dtype=tf.float32)\n",
    "    log_prob_ = target_distribution.log_prob(x_)\n",
    "    model = tfk.Model(x_, log_prob_)\n",
    "\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01),\n",
    "                  loss=lambda _, log_prob: -log_prob) \n",
    "    if(feedback):\n",
    "        print('---   Model compiled   ---')\n",
    "        print(\" - N samples = {}\".format(nsamples))\n",
    "        if weights.all()==weights[0]:\n",
    "            print(\" - Uniform weights = {}\".format(weights[0]))\n",
    "        else:\n",
    "            print(\" - Non-uniform weights\")\n",
    "        print(\" - Pre-Gaussian Map = True\\n\")\n",
    "        print(\" - Validation split = {}\".format(val_split))\n",
    "        print(' - Number MAFS = {} '.format(int(len(bijectors)/2)))\n",
    "        print(' - Trainable parameters = {} \\n'.format(model.count_params()))\n",
    "\n",
    "    # now perform the fit\n",
    "    if(feedback):\n",
    "        model.fit(x=x_data,\n",
    "                  y=np.zeros((nsamples, dim),dtype=np.float32),\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=n_epochs,\n",
    "                  steps_per_epoch=int(nsamples/batch_size*0.8),  # Usually `n // batch_size`.\n",
    "                  validation_split=val_split,\n",
    "                  shuffle=True,\n",
    "                  verbose=False,\n",
    "                  callbacks=[Callback(),tfk.callbacks.ReduceLROnPlateau()]) #, ydata\n",
    "    if(not feedback):\n",
    "        model.fit(x=x_data,\n",
    "                  y=np.zeros((nsamples, dim),dtype=np.float32),\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=n_epochs,\n",
    "                  steps_per_epoch=int(nsamples/batch_size*0.8),  # Usually `n // batch_size`.\n",
    "                  validation_split=val_split,\n",
    "                  shuffle=True,\n",
    "                  verbose=False,\n",
    "                  callbacks=[No_Plot_Callback(),tfk.callbacks.ReduceLROnPlateau()]) #, ydata\n",
    "        \n",
    "    return(target_distribution,bij)\n",
    "\n",
    "def setup(n_maf,n_params,permute,feedback=True):\n",
    "    # Set up bijector MADE\n",
    "    hidden_units=[n_params*2]*2\n",
    "    if(feedback):\n",
    "        print('---   MADE Info   ---')\n",
    "        print(' - Hidden_units = {}'.format(hidden_units))\n",
    "        print(' - Activation = {}\\n'.format(tf.math.asinh))\n",
    "    bijectors=[]\n",
    "    if(permute==True):\n",
    "        _permutations = [np.random.permutation(n_params) for _ in range(n_maf)]\n",
    "    else:\n",
    "        _permutations=False\n",
    "    \n",
    "    for i in range(n_maf):\n",
    "        # the permutation part comes from the code M. Raveri wrote,\n",
    "        if _permutations:\n",
    "            #print(_permutations[i])\n",
    "            bijectors.append(tfb.Permute(_permutations[i].astype(np.int32)))\n",
    "        # rest by myself\n",
    "        bijectors.append(tfb.MaskedAutoregressiveFlow(shift_and_log_scale_fn=tfb.AutoregressiveNetwork(params=2, event_shape=(n_params,), hidden_units=hidden_units, activation=tf.math.asinh, kernel_initializer='glorot_uniform')))\n",
    "        \n",
    "    return bijectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04091831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed no burn in\n",
      "---   MADE Info   ---\n",
      " - Hidden_units = [10, 10]\n",
      " - Activation = <function asinh at 0x7f639ed5b200>\n",
      "\n",
      "---   Model compiled   ---\n",
      " - N samples = 100\n",
      " - Uniform weights = 1.0\n",
      " - Pre-Gaussian Map = True\n",
      "\n",
      " - Validation split = 0.1\n",
      " - Number MAFS = 10 \n",
      " - Trainable parameters = 2800 \n",
      "\n",
      "[####################] Completed!                          \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine posterior\n",
    "names = ['logA', 'ns', 'H0', 'omegab', 'omegac']\n",
    "\n",
    "#  length_eg = samples[:100]\n",
    "train_chain = MCSamples(samples=length_eg[...,:5],names=names,labels=names)\n",
    "\n",
    "n_params = len(train_chain.getParamNames().list())\n",
    "dist = tfd.MultivariateNormalDiag(\n",
    "    loc=np.zeros(n_params,dtype=np.float32), \n",
    "    scale_diag=np.ones(n_params,dtype=np.float32))\n",
    "\n",
    "# make bijectors\n",
    "bijectors = setup(2*n_params,n_params,True)\n",
    "\n",
    "# train\n",
    "trained_dist,bijector = train(dist,train_chain,bijectors=bijectors,batch_size=10,n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8823e5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# Compute the posterior at each sample:\n",
    "posterior = trained_dist.log_prob(bijector.inverse(np.array(length_eg[...,:5],dtype=np.float32)))\n",
    "print(len(posterior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcc240ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evidence = 353.30255 +/- 19.63783\n"
     ]
    }
   ],
   "source": [
    "evidence = posterior - prior_lkl\n",
    "mean = np.mean(evidence)\n",
    "std = np.std(evidence)/np.sqrt(len(evidence))\n",
    "\n",
    "print('evidence = {:.5f} +/- {:.5f}'.format(mean,std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c3473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 100 \n",
      "Run 1/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 500 \n",
      "Run 2/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 1000 \n",
      "Run 3/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 5000 \n",
      "Run 4/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 10000 \n",
      "Run 5/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 20000 \n",
      "Run 6/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 30000 \n",
      "Run 7/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 40000 \n",
      "Run 8/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 50000 \n",
      "Run 9/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 75000 \n",
      "Run 10/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 100000 \n",
      "Run 11/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n",
      "length = 125000 \n",
      "Run 12/12\n",
      "Removed no burn in\n",
      "[####################] Completed!                             \n"
     ]
    }
   ],
   "source": [
    "#now lets just do this programatically:\n",
    "# data arr\n",
    "evidence = []\n",
    "error = []\n",
    "\n",
    "i=1\n",
    "# do the calculations\n",
    "for l in chain_lengths:\n",
    "    print('length = {} \\nRun {}/{}'.format(l,i,len(chain_lengths)))\n",
    "    # prior + likelihood\n",
    "    _samples = samples[:l]\n",
    "    prior_lkl = np.array([lnprob(s) for s in _samples])\n",
    "    \n",
    "    #posterior\n",
    "    train_chain = MCSamples(samples=_samples[...,:5],names=names,labels=names)\n",
    "\n",
    "    n_params = len(train_chain.getParamNames().list())\n",
    "    dist = tfd.MultivariateNormalDiag(\n",
    "        loc=np.zeros(n_params,dtype=np.float32), \n",
    "        scale_diag=np.ones(n_params,dtype=np.float32))\n",
    "\n",
    "    # make bijectors\n",
    "    bijectors = setup(2*n_params,n_params,True,feedback=False)\n",
    "    \n",
    "    if( l < 500 ):\n",
    "        batch_size = 10\n",
    "    elif( l< 10000 ):\n",
    "        batch_size = 100\n",
    "    else:\n",
    "        batch_size=1000\n",
    "\n",
    "    # train\n",
    "    trained_dist,bijector = train(dist,train_chain,bijectors=bijectors,batch_size=batch_size,n_epochs=100,feedback=False)\n",
    "    \n",
    "    posterior = trained_dist.log_prob(bijector.inverse(np.array(_samples[...,:5],dtype=np.float32)))\n",
    "    \n",
    "    e = posterior - prior_lkl\n",
    "    while(np.mean(e) == np.inf):\n",
    "        print('Mean evidence is infinite! Changing scale...')\n",
    "        print('Scale = {}'.format(j))\n",
    "        e = e/j\n",
    "        j=j*10\n",
    "        if( j>1e6 ):\n",
    "            print('scale > 1000000. Stopping...')\n",
    "            break\n",
    "    if( j>1e6 ):\n",
    "        break\n",
    "    evidence.append(j*np.mean(e))\n",
    "    error.append(j*np.std(e)/np.sqrt(len(evidence)))\n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddd4dacf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(chain_lengths,evidence,yerr=error,lw=0,elinewidth=2,marker='o',markersize=4)\n",
    "\n",
    "ax = plt.gca()\n",
    "#ax.set_ylim([0.8, 2.0])\n",
    "#ax.legend()\n",
    "plt.xlabel('N samples')\n",
    "plt.ylabel('$\\log(\\mathcal{E})$')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea3854fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137519.4656677246, 116893.34848022461, 92974.89973449707, 29339.005500793457, 17386.943996429443, 11264.112279891968, 9203.305894851685, 8130.229694366455, 7460.76117515564, 6642.313301086426, 6204.0947341918945, 5911.244409561157, 4935.211944580078, 4589.886225700378, 4386.337669372559]\n",
      "[76420.50898742676, 55516.02015803738, 41544.42342270653, 23948.089992523193, 15941.836826553566, 10582.435760172959, 8079.254129137612, 6588.194096894547, 5582.461523691813, 4370.9787116673715, 3634.3915557666096, 3129.710259567734, 2142.694570713133, 1488.7938948377466, 1031.3043083239822]\n"
     ]
    }
   ],
   "source": [
    "print(evidence)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f95b56ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(chain_lengths,evidence,yerr=error,lw=0,elinewidth=2,marker='o',markersize=4)\n",
    "\n",
    "ax = plt.gca()\n",
    "#ax.set_ylim([0.8, 2.0])\n",
    "#ax.legend()\n",
    "plt.xlabel('N samples')\n",
    "plt.ylabel('$\\log(\\mathcal{E})$')\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8ace7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_lengths = [1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7aadac27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length = 1000000 \n",
      "Run 1/1\n",
      "[                    ] 0% (0:00:05)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1656557/801133374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_samples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mprior_lkl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlnprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1656557/527077457.py\u001b[0m in \u001b[0;36mlnprob\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlnprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlnprior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mln_lkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data_vector_emu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1656557/527077457.py\u001b[0m in \u001b[0;36mln_lkl\u001b[0;34m(theta)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mmodel_datavector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_vector_emu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mdelta_dv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_datavector\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdv_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_3x2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdelta_dv\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdata_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_inv_cov\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mdelta_dv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlnprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i=1\n",
    "# do the calculations\n",
    "for l in extra_lengths:\n",
    "    start_time = datetime.datetime.now()\n",
    "    print('length = {} \\nRun {}/{}'.format(l,i,len(extra_lengths)))\n",
    "    # prior + likelihood\n",
    "    _samples = samples[:l]\n",
    "    prior_lkl = np.zeros(l)\n",
    "    for idx in range(l):\n",
    "        s = _samples[idx]\n",
    "        prior_lkl[idx] = lnprob(s)\n",
    "        if( idx % 10000 == 0 ):\n",
    "            continue\n",
    "        progress = int(idx/l*20)\n",
    "        ret = '\\r['\n",
    "        for k in range(progress):\n",
    "            ret += '#'\n",
    "        for k in range(20-progress):\n",
    "            ret += ' '\n",
    "        print(ret+'] {}% ({})'.format(int(idx/l*100),(datetime.datetime.now() - start_time)// 1000000 * 1000000),end=\"\")\n",
    "    print('')\n",
    "    #posterior\n",
    "    train_chain = MCSamples(samples=_samples[...,:5],names=names,labels=names)\n",
    "\n",
    "    n_params = len(train_chain.getParamNames().list())\n",
    "    dist = tfd.MultivariateNormalDiag(\n",
    "        loc=np.zeros(n_params,dtype=np.float32), \n",
    "        scale_diag=np.ones(n_params,dtype=np.float32))\n",
    "\n",
    "    # make bijectors\n",
    "    bijectors = setup(2*n_params,n_params,True,feedback=False)\n",
    "    \n",
    "    if( l < 500 ):\n",
    "        batch_size = 10\n",
    "    elif( l< 10000 ):\n",
    "        batch_size = 100\n",
    "    else:\n",
    "        batch_size=10000\n",
    "\n",
    "    # train\n",
    "    trained_dist,bijector = train(dist,train_chain,bijectors=bijectors,batch_size=batch_size,n_epochs=100,feedback=False)\n",
    "    \n",
    "    posterior = trained_dist.log_prob(bijector.inverse(np.array(_samples[...,:5],dtype=np.float32)))\n",
    "    \n",
    "    e = posterior - prior_lkl\n",
    "    while(np.mean(e) == np.inf):\n",
    "        print('Mean evidence is infinite! Changing scale...')\n",
    "        print('Scale = {}'.format(j))\n",
    "        e = e/j\n",
    "        j=j*10\n",
    "        if( j>1e6 ):\n",
    "            print('scale > 1000000. Stopping...')\n",
    "            break\n",
    "    if( j>1e6 ):\n",
    "        break\n",
    "    evidence.append(j*np.mean(e))\n",
    "    error.append(j*np.std(e)/np.sqrt(len(evidence)))\n",
    "    i+=1\n",
    "    chain_lengths.append(l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d06bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#evidence = [137519.4656677246, 116893.34848022461, 92974.89973449707, 29339.005500793457, 17386.943996429443, 11264.112279891968, 9203.305894851685, 8130.229694366455, 7460.76117515564, 6642.313301086426, 6204.0947341918945, 5911.244409561157]\n",
    "#error    = [76420.50898742676, 55516.02015803738, 41544.42342270653, 23948.089992523193, 15941.836826553566, 10582.435760172959, 8079.254129137612, 6588.194096894547, 5582.461523691813, 4370.9787116673715, 3634.3915557666096, 3129.710259567734]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emu",
   "language": "python",
   "name": "emu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
